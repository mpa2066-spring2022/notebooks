{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Assessing Classification Models</h1></center>\n",
    "<center><h1>Paul Stey</h1></center>\n",
    "<center><h1>2022-03-22</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is a good model?\n",
    "  * What is accuracy?\n",
    "  * What is our \"baseline\" accuracy?\n",
    "  * What other ways can we assess classification performance?\n",
    "      - Accuracy\n",
    "      - _F1_ score\n",
    "      - Sensitivity\n",
    "      - Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What is accuracy?\n",
    "\n",
    "![image](images/true_false_positive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example Definitions\n",
    "\n",
    "* _True Positive_: Sick people correctly identified as sick\n",
    "* _False Positive_: Healthy people incorrectly identified as sick\n",
    "* _True Negative_: Healthy people correctly identified as healthy\n",
    "* _False Negative_: Sick people incorrectly identified as healthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Accuracy (cont.)?\n",
    "\n",
    "![image](images/true_false_positive_general.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is Accuracy (cont.)?\n",
    "\n",
    "<br>\n",
    "<center>$\\LARGE{Accuracy = \\frac{TP + TN}{TP + TN + FN + FP}}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is \"baseline\" Accuracy?\n",
    "\n",
    "  * No diffinitive answer\n",
    "  * Basically, the accuracy we get with a \"simple model\"\n",
    "  * Predicting majority class for all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is a \"good\" Model?\n",
    "\n",
    "  * Is 99% accuracy good?\n",
    "    - Credit card transaction example\n",
    "  * What are doing with our model? And what kind of errors bother us more?\n",
    "    - Diagnosing disease? (prioritize minimizing false negative)\n",
    "    - Filtering spam email? (prioritize minimizing false positives)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sensitivity and Specificity\n",
    "\n",
    "* Going beyond just accuracy \n",
    "* Decide what kind of error are worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensitivity\n",
    "\n",
    "* Also known as: \"hit rate\", \"true-positive rate\", \"recall\"\n",
    "* Answers this question:\n",
    "  - _\"What proportion of the positive cases are we correctly identifying?\"_\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "    \n",
    "<center>$\\LARGE{Sensitivity = \\frac{TP}{TP + FN} =  \\frac{TP}{P}}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Specificity\n",
    "\n",
    "* Also known as: \"true-negative rate\"\n",
    "* Answers this question:\n",
    "  - _\"What proportion of the negative cases are we correctly identifying?\"_\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "    \n",
    "<center>$\\LARGE{Specificity = \\frac{TN}{TN + FP} =  \\frac{TN}{N}}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Specificity (cont.)\n",
    "\n",
    "  * Also important because _false positive rate_ is $1 - Specificity = \\frac{FP}{FP + TN}$\n",
    "  * And minimizing false positives is often important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is a \"good\" Model (cont.)?\n",
    "\n",
    "* It depends.\n",
    "* A good model is one that: \n",
    "  - is useful\n",
    "  - satisfies our requirements\n",
    "  - is wrong in the \"better\" way for our problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Challenge Question</h1></center>\n",
    "\n",
    "Let's write a function callend `sensitivity()` that computes the sensitivity of a classifier model's predicted output. Our function should take two arguments: `y` and `y_hat`, which are NumPy arrays. The function should then  return a value between `0` and `1` indicating the model's sensitivity.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>$\\Large{Sensitivity = \\frac{TP}{TP + FN} =  \\frac{TP}{P}}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Write our function here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing our function\n",
    "import numpy as np\n",
    "\n",
    "y1 = np.array([1, 1, 0, 0, 1, 1]) # this is our ground truth (i.e., `y`)\n",
    "y2 = np.array([1, 0, 0, 1, 1, 1]) # this is our prediction (i.e., `y_hat`)\n",
    "\n",
    "sensitivity(y1, y2)               # should print `0.75`"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
